{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_example_gan_cifar10.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"FReGwf7-rNDB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":575},"outputId":"3b9e627f-2f50-4d69-8119-48406ce9da9e","executionInfo":{"status":"ok","timestamp":1541001975424,"user_tz":-540,"elapsed":9249,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["!pip install keras==2.0.1\n","!pip install git+https://github.com/bstriner/keras-adversarial.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting keras==2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/bf/e440710b86a5a90d5ec5823ed9e0bafd8f199c5a1f77f7b0f7d76ce555ee/Keras-2.0.1.tar.gz (192kB)\n","\u001b[K    100% |████████████████████████████████| 194kB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==2.0.1) (1.0.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.1) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==2.0.1) (1.11.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.1) (1.14.6)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.1) (0.19.1)\n","Building wheels for collected packages: keras\n","  Running setup.py bdist_wheel for keras ... \u001b[?25l-\b \b\\\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c2/be/39/81d0b27e26aef72f012ae54263dda355f75bb1f0c2eff64264\n","Successfully built keras\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.1.6\n","    Uninstalling Keras-2.1.6:\n","      Successfully uninstalled Keras-2.1.6\n","Successfully installed keras-2.0.1\n","Collecting git+https://github.com/bstriner/keras-adversarial.git\n","  Cloning https://github.com/bstriner/keras-adversarial.git to /tmp/pip-req-build-dgbgv1h2\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-adversarial==0.0.3) (2.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adversarial==0.0.3) (1.11.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adversarial==0.0.3) (3.13)\n","Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adversarial==0.0.3) (1.0.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->Keras->keras-adversarial==0.0.3) (1.14.6)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->Keras->keras-adversarial==0.0.3) (0.19.1)\n","Building wheels for collected packages: keras-adversarial\n","  Running setup.py bdist_wheel for keras-adversarial ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-hfy9q0ft/wheels/f4/34/ba/6041a92244597803d1f8954d649e7899d011d46f33c02dc476\n","Successfully built keras-adversarial\n","Installing collected packages: keras-adversarial\n","Successfully installed keras-adversarial-0.0.3\n"],"name":"stdout"}]},{"metadata":{"id":"pgqk_ThUrFTr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ededf818-f879-4063-f699-c9280a280470","executionInfo":{"status":"ok","timestamp":1541001977656,"user_tz":-540,"elapsed":2155,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["import numpy as np\n","import keras.backend as K\n","from keras.layers import Input, Reshape\n","\n","\n","def dim_ordering_fix(x):\n","    if K.image_dim_ordering() == 'th':\n","        return x\n","    else:\n","        return np.transpose(x, (0, 2, 3, 1))\n","\n","\n","def dim_ordering_unfix(x):\n","    if K.image_dim_ordering() == 'th':\n","        return x\n","    else:\n","        return np.transpose(x, (0, 3, 1, 2))\n","\n","\n","def dim_ordering_shape(input_shape):\n","    if K.image_dim_ordering() == 'th':\n","        return input_shape\n","    else:\n","        return (input_shape[1], input_shape[2], input_shape[0])\n","\n","\n","def dim_ordering_input(input_shape, name):\n","    if K.image_dim_ordering() == 'th':\n","        return Input(input_shape, name=name)\n","    else:\n","        return Input((input_shape[1], input_shape[2], input_shape[0]), name=name)\n","\n","\n","def dim_ordering_reshape(k, w, **kwargs):\n","    if K.image_dim_ordering() == 'th':\n","        return Reshape((k, w, w), **kwargs)\n","    else:\n","        return Reshape((w, w, k), **kwargs)\n","\n","\n","def channel_axis():\n","    if K.image_dim_ordering() == 'th':\n","        return 1\n","    else:\n","        return 3"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"7KBhd8nIrQQq","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib as mpl\n","import keras.backend as K\n","from keras.layers import Reshape, Flatten, LeakyReLU, Activation, Dense, BatchNormalization, SpatialDropout2D\n","from keras.layers.convolutional import Conv2D, UpSampling2D, MaxPooling2D, AveragePooling2D\n","from keras.regularizers import L1L2\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard\n","from keras.datasets import cifar10\n","from keras_adversarial.image_grid_callback import ImageGridCallback\n","from keras_adversarial import AdversarialModel, simple_gan, gan_targets, fix_names\n","from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WeGOAvMMzgcR","colab_type":"code","colab":{}},"cell_type":"code","source":["def model_generator():\n","    model = Sequential()\n","    nch = 256\n","    reg = lambda: L1L2(l1=1e-7, l2=1e-7)\n","    h = 5\n","    model.add(Dense(nch * 4 * 4, input_dim=100, kernel_regularizer=reg()))\n","    model.add(BatchNormalization())\n","    model.add(Reshape(dim_ordering_shape((nch, 4, 4))))\n","    model.add(Conv2D(int(nch / 2), (h, h), padding=\"same\", kernel_regularizer=reg()))\n","    model.add(BatchNormalization())\n","    model.add(LeakyReLU(0.2))\n","    model.add(UpSampling2D(size=(2, 2)))\n","    model.add(Conv2D(int(nch / 2), (h, h), padding=\"same\", kernel_regularizer=reg()))\n","    model.add(BatchNormalization())\n","    model.add(LeakyReLU(0.2))\n","    model.add(UpSampling2D(size=(2, 2)))\n","    model.add(Conv2D(int(nch / 4), (h, h), padding=\"same\", kernel_regularizer=reg()))\n","    model.add(BatchNormalization())\n","    model.add(LeakyReLU(0.2))\n","    model.add(UpSampling2D(size=(2, 2)))\n","    model.add(Conv2D(3, (h, h), padding=\"same\", kernel_regularizer=reg()))\n","    model.add(Activation(\"sigmoid\"))\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zg2gnwKsziQ-","colab_type":"code","colab":{}},"cell_type":"code","source":["def model_discriminator():\n","    nch = 256\n","    h = 5\n","    reg = lambda: L1L2(l1=1e-7, l2=1e-7)\n","\n","    c1 = Conv2D(int(nch / 4),\n","                (h, h),\n","                padding=\"same\",\n","                kernel_regularizer=reg(),\n","                input_shape=dim_ordering_shape((3, 32, 32)))\n","    c2 = Conv2D(int(nch / 2),\n","                (h, h),\n","                padding=\"same\",\n","                kernel_regularizer=reg())\n","    c3 = Conv2D(nch,\n","                (h, h),\n","                padding=\"same\",\n","                kernel_regularizer=reg())\n","    c4 = Conv2D(1,\n","                (h, h),\n","                padding=\"same\",\n","                kernel_regularizer=reg())\n","\n","    def m(dropout):\n","        model = Sequential()\n","        model.add(c1)\n","        model.add(SpatialDropout2D(dropout))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(LeakyReLU(0.2))\n","        model.add(c2)\n","        model.add(SpatialDropout2D(dropout))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(LeakyReLU(0.2))\n","        model.add(c3)\n","        model.add(SpatialDropout2D(dropout))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(LeakyReLU(0.2))\n","        model.add(c4)\n","        model.add(AveragePooling2D(pool_size=(4, 4), padding=\"valid\"))\n","        model.add(Flatten())\n","        model.add(Activation(\"sigmoid\"))\n","        return model\n","    return m"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dzJSj4qazlrm","colab_type":"code","colab":{}},"cell_type":"code","source":["def cifar10_process(x):\n","    x = x.astype(np.float32) / 255.0\n","    return x\n","\n","\n","def cifar10_data():\n","    (xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n","    return cifar10_process(xtrain), cifar10_process(xtest)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9qS15--Ozo2z","colab_type":"code","colab":{}},"cell_type":"code","source":["def example_gan(adversarial_optimizer, path, opt_g, opt_d, nb_epoch,\n","                generator, discriminator, latent_dim,\n","                targets=gan_targets, loss=\"binary_crossentropy\"):\n","    csvpath = os.path.join(path, \"history.csv\")\n","    if os.path.exists(csvpath):\n","        print(\"Already exists: {}\".format(csvpath))\n","        return\n","\n","    print(\"Training: {}\".format(csvpath))\n","    # gan (x - > yfake, yreal), z is gaussian generated on GPU\n","    # can also experiment with uniform_latent_sampling\n","    d_g = discriminator(0)\n","    d_d = discriminator(0.5)\n","    generator.summary()\n","    d_d.summary()\n","    gan_g = simple_gan(generator, d_g, None)\n","    gan_d = simple_gan(generator, d_d, None)\n","    x = gan_g.inputs[1]\n","    z = normal_latent_sampling((latent_dim,))(x)\n","    # estiminate z from inputs\n","    gan_g = Model([x], fix_names(gan_g([z, x]), gan_g.output_names))\n","    gan_d = Model([x], fix_names(gan_d([z, x]), gan_d.output_names))\n","\n","    # build adversarial model\n","    model = AdversarialModel(player_models=[gan_g, gan_d],\n","                             player_params=[generator.trainable_weights,\n","                                            d_d.trainable_weights],\n","                             player_names=[\"generator\", \"discriminator\"])\n","    model.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n","                              player_optimizers=[opt_g, opt_d],\n","                              loss=loss)\n","\n","    # create callback to generate images\n","    zsamples = np.random.normal(size=(10 * 10, latent_dim))\n","\n","    def generator_sampler():\n","        xpred = generator.predict(zsamples)\n","        xpred = dim_ordering_unfix(xpred.transpose((0, 2, 3, 1)))\n","        return xpred.reshape((10, 10) + xpred.shape[1:])\n","\n","    generator_cb = ImageGridCallback(\n","                    os.path.join(path, \"epoch-{:03d}.png\"),\n","                    generator_sampler, cmap=None)\n","\n","    callbacks = [generator_cb]\n","    if K.backend() == \"tensorflow\":\n","        callbacks.append(\n","            TensorBoard(log_dir=os.path.join(path, \"logs\"),\n","                        histogram_freq=0, write_graph=True, write_images=True))\n","\n","    # train model\n","    xtrain, xtest = cifar10_data()\n","    y = targets(xtrain.shape[0])\n","    ytest = targets(xtest.shape[0])\n","    history = model.fit(x=xtrain, y=y, validation_data=(xtest, ytest),\n","                        callbacks=callbacks, epochs=nb_epoch,\n","                        batch_size=32)\n","\n","    # save history to CSV\n","    df = pd.DataFrame(history.history)\n","    df.to_csv(csvpath)\n","\n","    # save models\n","    generator.save(os.path.join(path, \"generator.h5\"))\n","    d_d.save(os.path.join(path, \"discriminator.h5\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9wW_1WJE0_ze","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"outputId":"a29730ea-8b4b-4999-85a4-27c3b7c73869","executionInfo":{"status":"ok","timestamp":1541001995783,"user_tz":-540,"elapsed":4348,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip"],"execution_count":8,"outputs":[{"output_type":"stream","text":["--2018-10-31 16:06:32--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.204.22.7, 34.196.224.14, 52.20.145.121, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.204.22.7|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5363700 (5.1M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]   5.11M  9.64MB/s    in 0.5s    \n","\n","2018-10-31 16:06:32 (9.64 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"metadata":{"id":"D2PKqz7N0AI5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"438f4378-0da8-4d41-cb16-b1c81eb119a3","executionInfo":{"status":"ok","timestamp":1541002375074,"user_tz":-540,"elapsed":2053,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["get_ipython().system_raw('tensorboard --logdir ./output/gan-cifar10/logs --host 0.0.0.0 --port 6006 &')\n","get_ipython().system_raw('./ngrok http 6006 &') # run nrok to tunnel tensorboard to outside world\n","\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":11,"outputs":[{"output_type":"stream","text":["http://c6bf09bc.ngrok.io\n"],"name":"stdout"}]},{"metadata":{"id":"Uu-abB6ArB4J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3252},"outputId":"4ab5a916-c237-4487-f046-95245418ab7e","executionInfo":{"status":"error","timestamp":1541002369570,"user_tz":-540,"elapsed":371103,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# z \\in R^100\n","latent_dim = 100\n","# x \\in R^{28x28}\n","# generator (z -> x)\n","generator = model_generator()\n","# discriminator (x -> y)\n","discriminator = model_discriminator()\n","if not os.path.exists(\"output\"):\n","    os.mkdir(\"output\")\n","if not os.path.exists(\"output/gan-cifar10\"):\n","    os.mkdir(\"output/gan-cifar10\")\n","example_gan(AdversarialOptimizerSimultaneous(), \"output/gan-cifar10\",\n","            opt_g=Adam(1e-4, decay=1e-5),\n","            opt_d=Adam(1e-3, decay=1e-5),\n","            nb_epoch=100, generator=generator, discriminator=discriminator,\n","            latent_dim=latent_dim)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1044: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Training: output/gan-cifar10/history.csv\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1062: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 4096)              413696    \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 4096)              16384     \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 4, 4, 128)         819328    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 8, 8, 128)         409728    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 16, 16, 64)        204864    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 32, 32, 3)         4803      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 3)         0         \n","=================================================================\n","Total params: 1,870,083.0\n","Trainable params: 1,861,251.0\n","Non-trainable params: 8,832.0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 32, 32, 64)        4864      \n","_________________________________________________________________\n","spatial_dropout2d_4 (Spatial (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 16, 16, 128)       204928    \n","_________________________________________________________________\n","spatial_dropout2d_5 (Spatial (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)    (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 8, 8, 256)         819456    \n","_________________________________________________________________\n","spatial_dropout2d_6 (Spatial (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)    (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 4, 4, 1)           6401      \n","_________________________________________________________________\n","average_pooling2d_2 (Average (None, 1, 1, 1)           0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 1)                 0         \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 1,035,649.0\n","Trainable params: 1,035,649.0\n","Non-trainable params: 0.0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1123: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Untaring file...\n","WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/100\n","50000/50000 [==============================] - 163s - loss: 5.6811 - generator_loss: 4.7992 - generator_yfake_loss: 2.1060 - generator_yreal_loss: 2.6713 - discriminator_loss: 0.8819 - discriminator_yfake_loss: 0.4098 - discriminator_yreal_loss: 0.4502 - val_loss: 4.5575 - val_generator_loss: 3.8496 - val_generator_yfake_loss: 2.1509 - val_generator_yreal_loss: 1.6711 - val_discriminator_loss: 0.7079 - val_discriminator_yfake_loss: 0.1394 - val_discriminator_yreal_loss: 0.5409\n","Epoch 2/100\n","45280/50000 [==========================>...] - ETA: 13s - loss: 5.8806 - generator_loss: 4.9916 - generator_yfake_loss: 2.1176 - generator_yreal_loss: 2.8428 - discriminator_loss: 0.8890 - discriminator_yfake_loss: 0.4131 - discriminator_yreal_loss: 0.4447"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-45cb353874a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mopt_d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             latent_dim=latent_dim)\n\u001b[0m","\u001b[0;32m<ipython-input-7-e875c9ecaf02>\u001b[0m in \u001b[0;36mexample_gan\u001b[0;34m(adversarial_optimizer, path, opt_g, opt_d, nb_epoch, generator, discriminator, latent_dim, targets, loss)\u001b[0m\n\u001b[1;32m     55\u001b[0m     history = model.fit(x=xtrain, y=y, validation_data=(xtest, ytest),\n\u001b[1;32m     56\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                         batch_size=32)\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# save history to CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"yBujSpfK1cMa","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}