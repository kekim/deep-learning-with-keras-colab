{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_umich_sentiment_lstm.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"pTQ9gHFuh6pE","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget https://raw.githubusercontent.com/chen0040/keras-sentiment-analysis-web-api/master/demo/data/umich-sentiment-train.txt -P ./data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gwYvFYrLiHOE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d1219b5c-59e5-492a-b2bd-45543f0d0be2","executionInfo":{"status":"ok","timestamp":1541398938100,"user_tz":-540,"elapsed":2158,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","from __future__ import division, print_function\n","import collections\n","import os\n","\n","import nltk\n","import numpy as np\n","from keras.callbacks import TensorBoard\n","from keras.layers import Activation, Dense, Dropout, Embedding, LSTM\n","from keras.models import Sequential\n","from keras.preprocessing import sequence\n","from sklearn.model_selection import train_test_split\n","import codecs"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"EtLGeFqciK4g","colab_type":"code","colab":{}},"cell_type":"code","source":["DATA_DIR = \"./data\"\n","LOG_DIR = \"./logs\"\n","\n","MAX_FEATURES = 2000\n","MAX_SENTENCE_LENGTH = 40\n","\n","EMBEDDING_SIZE = 128\n","HIDDEN_LAYER_SIZE = 64\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 10"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iaRuC9YOiMyS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"8610bf9e-b988-465a-bae8-9aa703fb3745","executionInfo":{"status":"ok","timestamp":1541398952743,"user_tz":-540,"elapsed":3404,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# Read training data and generate vocabulary\n","maxlen = 0\n","word_freqs = collections.Counter()\n","num_recs = 0\n","with codecs.open(os.path.join(DATA_DIR, \"umich-sentiment-train.txt\"), \"r\",\n","                 'utf-8') as ftrain:\n","    for line in ftrain:\n","        label, sentence = line.strip().split(\"\\t\")\n","        try:\n","            words = nltk.word_tokenize(sentence.lower())\n","        except LookupError:\n","            print(\"Englisth tokenize does not downloaded. So download it.\")\n","            nltk.download(\"punkt\")\n","            words = nltk.word_tokenize(sentence.lower())\n","        maxlen = max(maxlen, len(words))\n","        for word in words:\n","            word_freqs[word] += 1\n","        num_recs += 1\n","\n","# Get some information about our corpus\n","print(maxlen)            # 42\n","print(len(word_freqs))   # 2313\n","\n","# 1 is UNK, 0 is PAD\n","# We take MAX_FEATURES-1 features to account for PAD\n","vocab_size = min(MAX_FEATURES, len(word_freqs)) + 2\n","word2index = {x[0]: i+2 for i, x in\n","              enumerate(word_freqs.most_common(MAX_FEATURES))}\n","word2index[\"PAD\"] = 0\n","word2index[\"UNK\"] = 1\n","index2word = {v: k for k, v in word2index.items()}\n","\n","# convert sentences to sequences\n","X = np.empty((num_recs, ), dtype=list)\n","y = np.zeros((num_recs, ))\n","i = 0\n","with codecs.open(os.path.join(DATA_DIR, \"umich-sentiment-train.txt\"),\n","                 'r', 'utf-8') as ftrain:\n","    for line in ftrain:\n","        label, sentence = line.strip().split(\"\\t\")\n","        words = nltk.word_tokenize(sentence.lower())\n","        seqs = []\n","        for word in words:\n","            if word in word2index:\n","                seqs.append(word2index[word])\n","            else:\n","                seqs.append(word2index[\"UNK\"])\n","        X[i] = seqs\n","        y[i] = int(label)\n","        i += 1\n","\n","# Pad the sequences (left padded with zeros)\n","X = sequence.pad_sequences(X, maxlen=MAX_SENTENCE_LENGTH)\n","\n","# Split input into training and test\n","Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2,\n","                                                random_state=42)\n","print(Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["42\n","2328\n","(5668, 40) (1418, 40) (5668,) (1418,)\n"],"name":"stdout"}]},{"metadata":{"id":"CzthU-OfiYyh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"4b403614-f4c4-483d-9d72-3d88a3fb7a53","executionInfo":{"status":"ok","timestamp":1541398974135,"user_tz":-540,"elapsed":1128,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# Build model\n","model = Sequential()\n","model.add(Embedding(vocab_size, EMBEDDING_SIZE,\n","                    input_length=MAX_SENTENCE_LENGTH))\n","model.add(Dropout(0.5))\n","model.add(LSTM(HIDDEN_LAYER_SIZE, dropout=0.5, recurrent_dropout=0.5))\n","model.add(Dense(1))\n","model.add(Activation(\"sigmoid\"))\n","model.summary()\n","\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n","              metrics=[\"accuracy\"])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 40, 128)           256256    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 40, 128)           0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 64)                49408     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 65        \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 305,729\n","Trainable params: 305,729\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"5imYRjPeihqz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":395},"outputId":"6185a842-5b78-4849-8e7d-2dbe86e63805","executionInfo":{"status":"ok","timestamp":1541399272650,"user_tz":-540,"elapsed":265763,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["history = model.fit(Xtrain, ytrain, batch_size=BATCH_SIZE,\n","                    epochs=NUM_EPOCHS,\n","                    callbacks=[TensorBoard(LOG_DIR)],\n","                    validation_data=(Xtest, ytest))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Train on 5668 samples, validate on 1418 samples\n","Epoch 1/10\n","5668/5668 [==============================] - 27s 5ms/step - loss: 0.3090 - acc: 0.8615 - val_loss: 0.0891 - val_acc: 0.9669\n","Epoch 2/10\n","5668/5668 [==============================] - 25s 4ms/step - loss: 0.0515 - acc: 0.9832 - val_loss: 0.0562 - val_acc: 0.9788\n","Epoch 3/10\n","5668/5668 [==============================] - 25s 4ms/step - loss: 0.0249 - acc: 0.9908 - val_loss: 0.0455 - val_acc: 0.9831\n","Epoch 4/10\n","5668/5668 [==============================] - 25s 4ms/step - loss: 0.0200 - acc: 0.9944 - val_loss: 0.0458 - val_acc: 0.9810\n","Epoch 5/10\n","5668/5668 [==============================] - 26s 5ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0442 - val_acc: 0.9859\n","Epoch 6/10\n","5668/5668 [==============================] - 25s 4ms/step - loss: 0.0092 - acc: 0.9982 - val_loss: 0.0436 - val_acc: 0.9859\n","Epoch 7/10\n","5668/5668 [==============================] - 26s 4ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0485 - val_acc: 0.9887\n","Epoch 8/10\n","5668/5668 [==============================] - 26s 5ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0444 - val_acc: 0.9880\n","Epoch 9/10\n","5668/5668 [==============================] - 26s 5ms/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0464 - val_acc: 0.9880\n","Epoch 10/10\n","5668/5668 [==============================] - 25s 4ms/step - loss: 0.0030 - acc: 0.9995 - val_loss: 0.0430 - val_acc: 0.9901\n"],"name":"stdout"}]},{"metadata":{"id":"2cCcFgUgh5lQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"d56841f1-1e66-4a1c-bfdf-ac2031acfd58","executionInfo":{"status":"ok","timestamp":1541399367492,"user_tz":-540,"elapsed":2295,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# evaluate\n","score, acc = model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE)\n","print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(score, acc))\n","\n","for i in range(5):\n","    idx = np.random.randint(len(Xtest))\n","    xtest = Xtest[idx].reshape(1, 40)\n","    ylabel = ytest[idx]\n","    ypred = model.predict(xtest)[0][0]\n","    sent = \" \".join([index2word[x] for x in xtest[0].tolist() if x != 0])\n","    print(\"{:.0f}\\t{:.0f}\\t{}\".format(ypred, ylabel, sent))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["1418/1418 [==============================] - 2s 1ms/step\n","Test score: 0.043, accuracy: 0.990\n","1\t1\tand mission impossible orig tv shows are really awesome ... ... .\n","0\t0\teveryone knows brokeback mountain is going to win all because of the stupid gay cowboys .\n","0\t0\tda vinci code sucks .\n","1\t1\tthe people who are worth it know how much i love the da vinci code .\n","0\t0\tby the way , the da vinci code sucked , just letting you know ...\n"],"name":"stdout"}]},{"metadata":{"id":"zi9TsVZvguJl","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}