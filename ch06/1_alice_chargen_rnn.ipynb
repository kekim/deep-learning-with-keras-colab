{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_alice_chargen_rnn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"mAsRf4iafuLT","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget http://www.gutenberg.org/files/11/11-0.txt -O ./data/alice_in_wonderland.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AXGd3SiWf2AA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"f7d2695a-2054-48ed-ca6b-e39b5b0df5db","executionInfo":{"status":"ok","timestamp":1541398488581,"user_tz":-540,"elapsed":1578,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["from __future__ import print_function\n","\n","import numpy as np\n","from keras.layers import Dense, Activation, SimpleRNN\n","from keras.models import Sequential\n","import codecs\n","\n","\n","INPUT_FILE = \"./data/alice_in_wonderland.txt\"\n","\n","# extract the input as a stream of characters\n","print(\"Extracting text from input...\")\n","with codecs.open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n","    lines = [line.strip().lower() for line in f\n","             if len(line) != 0]\n","    text = \" \".join(lines)\n","\n","# creating lookup tables\n","# Here chars is the number of features in our character \"vocabulary\"\n","chars = set(text)\n","nb_chars = len(chars)\n","char2index = dict((c, i) for i, c in enumerate(chars))\n","index2char = dict((i, c) for i, c in enumerate(chars))\n","\n","# create inputs and labels from the text. We do this by stepping\n","# through the text ${step} character at a time, and extracting a\n","# sequence of size ${seqlen} and the next output char. For example,\n","# assuming an input text \"The sky was falling\", we would get the\n","# following sequence of input_chars and label_chars (first 5 only)\n","#   The sky wa -> s\n","#   he sky was ->\n","#   e sky was  -> f\n","#    sky was f -> a\n","#   sky was fa -> l\n","print(\"Creating input and label text...\")\n","SEQLEN = 10\n","STEP = 1\n","\n","input_chars = []\n","label_chars = []\n","for i in range(0, len(text) - SEQLEN, STEP):\n","    input_chars.append(text[i:i + SEQLEN])\n","    label_chars.append(text[i + SEQLEN])\n","    \n","print('input_0: ', input_chars[0])\n","print('label_0: ', label_chars[0])\n","\n","# vectorize the input and label chars\n","# Each row of the input is represented by seqlen characters, each\n","# represented as a 1-hot encoding of size len(char). There are\n","# len(input_chars) such rows, so shape(X) is (len(input_chars),\n","# seqlen, nb_chars).\n","# Each row of output is a single character, also represented as a\n","# dense encoding of size len(char). Hence shape(y) is (len(input_chars),\n","# nb_chars).\n","print(\"Vectorizing input and label text...\")\n","X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n","y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n","for i, input_char in enumerate(input_chars):\n","    for j, ch in enumerate(input_char):\n","        X[i, j, char2index[ch]] = 1\n","    y[i, char2index[label_chars[i]]] = 1"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Extracting text from input...\n","Creating input and label text...\n","input_0:  ﻿project g\n","label_0:  u\n","Vectorizing input and label text...\n"],"name":"stdout"}]},{"metadata":{"id":"8qWbkY6BgovE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"outputId":"71955fe9-2a89-499f-ce2b-58db010924d4","executionInfo":{"status":"ok","timestamp":1541398508189,"user_tz":-540,"elapsed":630,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# Build the model. We use a single RNN with a fully connected layer\n","# to compute the most likely predicted output char\n","HIDDEN_SIZE = 128\n","BATCH_SIZE = 128\n","NUM_ITERATIONS = 25\n","NUM_EPOCHS_PER_ITERATION = 1\n","NUM_PREDS_PER_EPOCH = 100\n","\n","model = Sequential()\n","model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n","                    input_shape=(SEQLEN, nb_chars),\n","                    unroll=True))\n","model.add(Dense(nb_chars))\n","model.add(Activation(\"softmax\"))\n","model.summary()\n","\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","simple_rnn_1 (SimpleRNN)     (None, 128)               24192     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 60)                7740      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 60)                0         \n","=================================================================\n","Total params: 31,932\n","Trainable params: 31,932\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"LL7R82zcfr3f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2717},"outputId":"713a8c0d-d9a9-4c84-fc93-528d03e5d332","executionInfo":{"status":"ok","timestamp":1541398791648,"user_tz":-540,"elapsed":271176,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# We train the model in batches and test output generated at each step\n","for iteration in range(NUM_ITERATIONS):\n","    print(\"=\" * 50)\n","    print(\"Iteration #: {}\".format(iteration))\n","    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n","\n","    # testing model\n","    # randomly choose a row from input_chars, then use it to\n","    # generate text from model for next 100 chars\n","    test_idx = np.random.randint(len(input_chars))\n","    test_chars = input_chars[test_idx]\n","    print(\"Generating from seed: {}\".format(test_chars))\n","    print(test_chars, end=\"\")\n","    for i in range(NUM_PREDS_PER_EPOCH):\n","        Xtest = np.zeros((1, SEQLEN, nb_chars))\n","        for j, ch in enumerate(test_chars):\n","            Xtest[0, j, char2index[ch]] = 1\n","        pred = model.predict(Xtest, verbose=0)[0]\n","        ypred = index2char[np.argmax(pred)]\n","        print(ypred, end=\"\")\n","        # move forward with test_chars + ypred\n","        test_chars = test_chars[1:] + ypred\n","    print()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["==================================================\n","Iteration #: 0\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 69us/step - loss: 2.3704\n","Generating from seed: , who had \n",", who had the the the the the the the the the the the the the the the the the the the the the the the the the \n","==================================================\n","Iteration #: 1\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 2.0625\n","Generating from seed: atching th\n","atching the she said the dore all at in the said the dore all at in the said the dore all at in the said the d\n","==================================================\n","Iteration #: 2\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 63us/step - loss: 1.9536\n","Generating from seed: t you, wil\n","t you, will a don the hat ere the mouthe her her her her her her her her her her her her her her her her her h\n","==================================================\n","Iteration #: 3\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 65us/step - loss: 1.8693\n","Generating from seed: e on the l\n","e on the liotle would be the way soo she was a lictle soo she was a lictle soo she was a lictle soo she was a \n","==================================================\n","Iteration #: 4\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 65us/step - loss: 1.8016\n","Generating from seed:  have you \n"," have you deand the mory the mouse she was a little see she had see chere the mory the mouse she was a little \n","==================================================\n","Iteration #: 5\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 66us/step - loss: 1.7442\n","Generating from seed: he sentenc\n","he sentence said the groject gutenberg-tm to be all the rabling to see all the rabling to see all the rabling \n","==================================================\n","Iteration #: 6\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.6979\n","Generating from seed: n.  if you\n","n.  if you had the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the m\n","==================================================\n","Iteration #: 7\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 68us/step - loss: 1.6580\n","Generating from seed: rg.org  th\n","rg.org  the realice of the realice of the realice of the realice of the realice of the realice of the realice \n","==================================================\n","Iteration #: 8\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 67us/step - loss: 1.6259\n","Generating from seed: er surpris\n","er surprise said the doch the could said the doch the could said the doch the could said the doch the could sa\n","==================================================\n","Iteration #: 9\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 65us/step - loss: 1.5972\n","Generating from seed: d memory, \n","d memory, and the project gutenberg-tm electronit was sook don’t grown the for of the project gutenberg-tm ele\n","==================================================\n","Iteration #: 10\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.5717\n","Generating from seed: ew a fryin\n","ew a frying to the king the door and the king the door and the king the door and the king the door and the kin\n","==================================================\n","Iteration #: 11\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 63us/step - loss: 1.5506\n","Generating from seed:  history. \n"," history.  ‘what it was a little said the mouse to herself hor the project gutenberg-tm the project gutenberg-\n","==================================================\n","Iteration #: 12\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.5320\n","Generating from seed: but it is.\n","but it is.’  ‘i don’t be the she had not little the door as she said the king the cat all the thing the shreat\n","==================================================\n","Iteration #: 13\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.5146\n","Generating from seed:  ‘i don’t \n"," ‘i don’t herself and the caterpillar the project gutenberg-tm electronic works to the grown the mock turtle s\n","==================================================\n","Iteration #: 14\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 65us/step - loss: 1.4981\n","Generating from seed: usion, get\n","usion, get in a don’t had not to the dormouse it was not look at the direction again to alice said the dormous\n","==================================================\n","Iteration #: 15\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.4857\n","Generating from seed:  the paper\n"," the paper of the table go down and said to the gryphon, and she was a little the door all the gryphon, and sh\n","==================================================\n","Iteration #: 16\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 63us/step - loss: 1.4721\n","Generating from seed: a lory and\n","a lory and she was a little seats of the project gutenberg-tm electronic work to herself her eved and the cate\n","==================================================\n","Iteration #: 17\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.4607\n","Generating from seed: ordering o\n","ordering of the gryphon in a ter southing souttine sure the for the for the for the for the for the for the fo\n","==================================================\n","Iteration #: 18\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.4501\n","Generating from seed: n! mary an\n","n! mary and she was a little the formenten to the rabbit had began to the door one of the round the caterpilla\n","==================================================\n","Iteration #: 19\n","Epoch 1/1\n","162739/162739 [==============================] - 11s 65us/step - loss: 1.4405\n","Generating from seed:  asked ali\n"," asked alice as she was all the caterpillar the expenting the caterpillar the expenting the caterpillar the ex\n","==================================================\n","Iteration #: 20\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 63us/step - loss: 1.4310\n","Generating from seed: he place w\n","he place was a little sit for a great croquet in a mouse to her fied, and the once in a long to herself, and t\n","==================================================\n","Iteration #: 21\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 63us/step - loss: 1.4234\n","Generating from seed: --i hardly\n","--i hardly to her face, and the mock turtle seem to for the mock turtle seem to for the mock turtle seem to fo\n","==================================================\n","Iteration #: 22\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.4151\n","Generating from seed: ire in sam\n","ire in same a little shan the sermage and as the once a little shan the sermage and as the once a little shan \n","==================================================\n","Iteration #: 23\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.4076\n","Generating from seed: e we chang\n","e we change to the cook the permons in the seated to the cook the permons in the seated to the cook the permon\n","==================================================\n","Iteration #: 24\n","Epoch 1/1\n","162739/162739 [==============================] - 10s 64us/step - loss: 1.4014\n","Generating from seed:  walked tw\n"," walked twat his hand as she said to herself, and she see that she had the sormouse it was great of the secter\n"],"name":"stdout"}]},{"metadata":{"id":"zi9TsVZvguJl","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}