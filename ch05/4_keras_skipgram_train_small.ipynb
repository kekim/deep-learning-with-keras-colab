{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_keras_skipgram_train_small.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"HFF8f2fXSHVq","colab_type":"code","outputId":"5e38bcfa-5485-483a-c8cd-20a8a7d3e24b","executionInfo":{"status":"ok","timestamp":1541210273816,"user_tz":-540,"elapsed":2858,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"cell_type":"code","source":["!mkdir data\n","!wget http://www.umich.edu/~umfandsf/other/ebooks/alice30.txt -O ./data/alice_in_wonderland.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2018-11-03 01:57:53--  http://www.umich.edu/~umfandsf/other/ebooks/alice30.txt\n","Resolving www.umich.edu (www.umich.edu)... 141.211.243.251, 2607:f018:1:1::1\n","Connecting to www.umich.edu (www.umich.edu)|141.211.243.251|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 148545 (145K) [text/plain]\n","Saving to: ‘./data/alice_in_wonderland.txt’\n","\n","\r          ./data/al   0%[                    ]       0  --.-KB/s               \r./data/alice_in_won 100%[===================>] 145.06K  --.-KB/s    in 0.1s    \n","\n","2018-11-03 01:57:53 (1.08 MB/s) - ‘./data/alice_in_wonderland.txt’ saved [148545/148545]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"_d8dJqVoWjcB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"779016e4-f72f-46fa-93f3-228c90c4a96d","executionInfo":{"status":"ok","timestamp":1541211338721,"user_tz":-540,"elapsed":5519,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","from __future__ import print_function\n","import operator\n","\n","import nltk\n","import numpy as np\n","from keras.callbacks import TensorBoard\n","from keras.layers import Dense, Dropout, Activation\n","from keras.models import Sequential\n","from keras.preprocessing.text import Tokenizer, one_hot\n","from sklearn.metrics.pairwise import cosine_distances\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","import codecs\n","\n","np.random.seed(42)\n","\n","LOG_DIR = './logs'\n","BATCH_SIZE = 128\n","NUM_EPOCHS = 20\n","\n","with codecs.open(\"./data/alice_in_wonderland.txt\", \"r\", encoding=\"utf-8\") as f:\n","    lines = [line.strip() for line in f if len(line) != 0]\n","\n","try:\n","    sents = nltk.sent_tokenize(\" \".join(lines))\n","except LookupError:\n","    print(\"Englisth tokenize does not downloaded. So download it.\")\n","    nltk.download(\"punkt\")\n","    sents = nltk.sent_tokenize(\" \".join(lines))\n","\n","\n","tokenizer = Tokenizer(5000)  # use top 5000 words only\n","tokens = tokenizer.fit_on_texts(sents)\n","vocab_size = len(tokenizer.word_counts) + 1\n","\n","xs = []\n","ys = []\n","for sent in sents:\n","    embedding = one_hot(sent, vocab_size)\n","    triples = list(nltk.trigrams(embedding))\n","    w_lefts = [x[0] for x in triples]\n","    w_centers = [x[1] for x in triples]\n","    w_rights = [x[2] for x in triples]\n","    xs.extend(w_centers)\n","    ys.extend(w_lefts)\n","    xs.extend(w_centers)\n","    ys.extend(w_rights)\n","\n","ohe = OneHotEncoder(n_values=vocab_size)\n","X = ohe.fit_transform(np.array(xs).reshape(-1, 1)).todense()\n","Y = ohe.fit_transform(np.array(ys).reshape(-1, 1)).todense()\n","Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3,\n","                                                random_state=42)\n","print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["(34402, 2653) (14744, 2653) (34402, 2653) (14744, 2653)\n"],"name":"stdout"}]},{"metadata":{"id":"oieQuAsQWqbG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"713b2b16-8e25-4990-9fc0-cf8635508010","executionInfo":{"status":"ok","timestamp":1541211450655,"user_tz":-540,"elapsed":642,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["model = Sequential()\n","model.add(Dense(300, input_shape=(Xtrain.shape[1],)))\n","model.add(Activation(\"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(Ytrain.shape[1]))\n","model.add(Activation(\"softmax\"))\n","model.summary()\n","\n","model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", \n","              metrics=[\"accuracy\"])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 300)               796200    \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 300)               0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 300)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2653)              798553    \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 2653)              0         \n","=================================================================\n","Total params: 1,594,753\n","Trainable params: 1,594,753\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"qF5fBVwyXELh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":775},"outputId":"1928751e-5f6a-49ff-f0f1-03ba88d40e5a","executionInfo":{"status":"ok","timestamp":1541211567643,"user_tz":-540,"elapsed":106774,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE, \n","                    epochs=NUM_EPOCHS, verbose=1,\n","                    callbacks=[TensorBoard(LOG_DIR)],\n","                    validation_data=(Xtest, Ytest))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Train on 34402 samples, validate on 14744 samples\n","Epoch 1/20\n","34402/34402 [==============================] - 4s 128us/step - loss: 6.1796 - acc: 0.0562 - val_loss: 5.7842 - val_acc: 0.0595\n","Epoch 2/20\n","34402/34402 [==============================] - 5s 145us/step - loss: 5.7016 - acc: 0.0609 - val_loss: 5.7336 - val_acc: 0.0657\n","Epoch 3/20\n","34402/34402 [==============================] - 5s 145us/step - loss: 5.6222 - acc: 0.0699 - val_loss: 5.6896 - val_acc: 0.0731\n","Epoch 4/20\n","34402/34402 [==============================] - 5s 149us/step - loss: 5.5529 - acc: 0.0778 - val_loss: 5.6509 - val_acc: 0.0809\n","Epoch 5/20\n","34402/34402 [==============================] - 5s 145us/step - loss: 5.4887 - acc: 0.0869 - val_loss: 5.6205 - val_acc: 0.0876\n","Epoch 6/20\n","34402/34402 [==============================] - 5s 140us/step - loss: 5.4333 - acc: 0.0963 - val_loss: 5.5986 - val_acc: 0.0932\n","Epoch 7/20\n","34402/34402 [==============================] - 5s 145us/step - loss: 5.3858 - acc: 0.1010 - val_loss: 5.5795 - val_acc: 0.0999\n","Epoch 8/20\n","34402/34402 [==============================] - 5s 141us/step - loss: 5.3451 - acc: 0.1058 - val_loss: 5.5660 - val_acc: 0.1002\n","Epoch 9/20\n","34402/34402 [==============================] - 5s 144us/step - loss: 5.3080 - acc: 0.1094 - val_loss: 5.5574 - val_acc: 0.1017\n","Epoch 10/20\n","34402/34402 [==============================] - 5s 145us/step - loss: 5.2794 - acc: 0.1111 - val_loss: 5.5417 - val_acc: 0.1036\n","Epoch 11/20\n","34402/34402 [==============================] - 5s 145us/step - loss: 5.2542 - acc: 0.1141 - val_loss: 5.5297 - val_acc: 0.1063\n","Epoch 12/20\n","34402/34402 [==============================] - 5s 147us/step - loss: 5.2263 - acc: 0.1167 - val_loss: 5.5225 - val_acc: 0.1073\n","Epoch 13/20\n","34402/34402 [==============================] - 5s 144us/step - loss: 5.2037 - acc: 0.1178 - val_loss: 5.5182 - val_acc: 0.1078\n","Epoch 14/20\n","34402/34402 [==============================] - 5s 147us/step - loss: 5.1842 - acc: 0.1189 - val_loss: 5.5212 - val_acc: 0.1089\n","Epoch 15/20\n","34402/34402 [==============================] - 5s 143us/step - loss: 5.1630 - acc: 0.1197 - val_loss: 5.5089 - val_acc: 0.1089\n","Epoch 16/20\n","34402/34402 [==============================] - 5s 145us/step - loss: 5.1485 - acc: 0.1207 - val_loss: 5.5005 - val_acc: 0.1087\n","Epoch 17/20\n","34402/34402 [==============================] - 5s 142us/step - loss: 5.1307 - acc: 0.1224 - val_loss: 5.5032 - val_acc: 0.1102\n","Epoch 18/20\n","34402/34402 [==============================] - 5s 144us/step - loss: 5.1152 - acc: 0.1225 - val_loss: 5.4932 - val_acc: 0.1093\n","Epoch 19/20\n","34402/34402 [==============================] - 5s 148us/step - loss: 5.0988 - acc: 0.1234 - val_loss: 5.4956 - val_acc: 0.1096\n","Epoch 20/20\n","34402/34402 [==============================] - 5s 144us/step - loss: 5.0914 - acc: 0.1235 - val_loss: 5.4928 - val_acc: 0.1104\n"],"name":"stdout"}]},{"metadata":{"id":"G6GEQVEmXLBs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"be797d90-2d83-4ef9-aab6-bb476e4caeac","executionInfo":{"status":"ok","timestamp":1541211577517,"user_tz":-540,"elapsed":3120,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# evaluate model\n","score = model.evaluate(Xtest, Ytest, verbose=1)\n","print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(score[0], score[1]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["14744/14744 [==============================] - 2s 160us/step\n","Test score: 5.493, accuracy: 0.110\n"],"name":"stdout"}]},{"metadata":{"id":"_wal_29DWbu3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"54ae5d26-2e5f-4366-aecf-3f9423401d4b","executionInfo":{"status":"ok","timestamp":1541211589201,"user_tz":-540,"elapsed":10851,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# using the word2vec model\n","word2idx = tokenizer.word_index\n","idx2word = {v: k for k, v in word2idx.items()}\n","\n","# retrieve the weights from the first dense layer. This will convert\n","# the input vector from a one-hot sum of two words to a dense 300 \n","# dimensional representation\n","W, b = model.layers[0].get_weights()\n","\n","idx2emb = {}    \n","for word in word2idx.keys():\n","    wid = word2idx[word]\n","    vec_in = ohe.fit_transform(np.array(wid)).todense()\n","    vec_emb = np.dot(vec_in, W)\n","    idx2emb[wid] = vec_emb\n","\n","for word in [\"stupid\", \"alice\", \"succeeded\"]:\n","    wid = word2idx[word]\n","    source_emb = idx2emb[wid]\n","    distances = []\n","    for i in range(1, vocab_size):\n","        if i == wid:\n","            continue\n","        target_emb = idx2emb[i]\n","        distances.append(((wid, i), \n","                         cosine_distances(source_emb, target_emb)))\n","    sorted_distances = sorted(distances, key=operator.itemgetter(1))[0:10]\n","    predictions = [idx2word[x[0][1]] for x in sorted_distances]\n","    print(\"{:s} => {:s}\".format(word, \", \".join(predictions)))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["stupid => here, tale, slowly, hurrying, quarrelled, forgetting, crowded, carried, lefthand, enormous\n","alice => her, speed, trials, happening, low, she, eyelids, geography, by, quiver\n","succeeded => doors, murder, irritated, memory, struck, respect, conquest, branches, leaders, she'll\n"],"name":"stdout"}]},{"metadata":{"id":"-7nCfeM1pKD0","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}