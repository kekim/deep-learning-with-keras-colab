{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7_learn_embedding_from_scratch_sentiment_analysis.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"-l4L-WPiUd14","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"89afcb2b-a7bb-493d-d8aa-88507b1f57cf","executionInfo":{"status":"ok","timestamp":1541395910216,"user_tz":-540,"elapsed":2580,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","from __future__ import print_function\n","import os\n","import collections\n","\n","import nltk\n","import numpy as np\n","from keras.callbacks import TensorBoard\n","from keras.layers import Dense, Dropout, Conv1D, Embedding, GlobalMaxPooling1D\n","from keras.models import Sequential\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","import codecs\n","\n","np.random.seed(42)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"KNIudl49Uhgh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"f20c8d33-f56f-4328-d610-f5793bc53d67","executionInfo":{"status":"ok","timestamp":1541395899807,"user_tz":-540,"elapsed":4432,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["!mkdir data\n","!wget https://raw.githubusercontent.com/chen0040/keras-sentiment-analysis-web-api/master/demo/data/umich-sentiment-train.txt -P ./data"],"execution_count":1,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘data’: File exists\n","--2018-11-05 05:31:38--  https://raw.githubusercontent.com/chen0040/keras-sentiment-analysis-web-api/master/demo/data/umich-sentiment-train.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 447539 (437K) [text/plain]\n","Saving to: ‘./data/umich-sentiment-train.txt’\n","\n","umich-sentiment-tra 100%[===================>] 437.05K  --.-KB/s    in 0.08s   \n","\n","2018-11-05 05:31:38 (5.14 MB/s) - ‘./data/umich-sentiment-train.txt’ saved [447539/447539]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"sZowdyxFWx7j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"2c28ba8d-c4d7-45e6-d3b4-67cdfaab94b0","executionInfo":{"status":"ok","timestamp":1541395931460,"user_tz":-540,"elapsed":4378,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["INPUT_FILE = \"./data/umich-sentiment-train.txt\"\n","LOG_DIR = \"./logs\"\n","VOCAB_SIZE = 5000\n","EMBED_SIZE = 100\n","NUM_FILTERS = 256\n","NUM_WORDS = 3\n","BATCH_SIZE = 64\n","NUM_EPOCHS = 20\n","\n","counter = collections.Counter()\n","with codecs.open(INPUT_FILE, \"r\", encoding=\"utf-8\") as fin:\n","    maxlen = 0\n","    for line in fin:\n","        _, sent = line.strip().split(\"\\t\")\n","        try:\n","            words = [x.lower() for x in nltk.word_tokenize(sent)]\n","        except LookupError:\n","            print(\"Englisth tokenize does not downloaded. So download it.\")\n","            nltk.download(\"punkt\")\n","            words = [x.lower() for x in nltk.word_tokenize(sent)]\n","        maxlen = max(maxlen, len(words))\n","        for word in words:\n","            counter[word] += 1\n","\n","word2index = collections.defaultdict(int)\n","for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n","    word2index[word[0]] = wid + 1\n","vocab_sz = len(word2index) + 1\n","index2word = {v: k for k, v in word2index.items()}\n","\n","xs, ys = [], []\n","with codecs.open(INPUT_FILE, \"r\", encoding=\"utf-8\") as fin:\n","    for line in fin:\n","        label, sent = line.strip().split(\"\\t\")\n","        ys.append(int(label))\n","        words = [x.lower() for x in nltk.word_tokenize(sent)]\n","        wids = [word2index[word] for word in words]\n","        xs.append(wids)\n","\n","X = pad_sequences(xs, maxlen=maxlen)\n","Y = np_utils.to_categorical(ys)\n","\n","Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3, \n","                                                random_state=42)\n","print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Englisth tokenize does not downloaded. So download it.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","(4960, 42) (2126, 42) (4960, 2) (2126, 2)\n"],"name":"stdout"}]},{"metadata":{"id":"0Povm0MsUcd_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"18bef63d-6efc-4392-e606-659bb43a633a","executionInfo":{"status":"ok","timestamp":1541395980119,"user_tz":-540,"elapsed":650,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(vocab_sz, EMBED_SIZE, input_length=maxlen))\n","model.add(Dropout(0.2))\n","model.add(Conv1D(filters=NUM_FILTERS, kernel_size=NUM_WORDS, activation=\"relu\"))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dense(2, activation=\"softmax\"))\n","model.summary()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 42, 100)           232900    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 42, 100)           0         \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 40, 256)           77056     \n","_________________________________________________________________\n","global_max_pooling1d_1 (Glob (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 514       \n","=================================================================\n","Total params: 310,470\n","Trainable params: 310,470\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"TTN8w1p2W8Od","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":791},"outputId":"d0175786-4dc6-4e34-f07f-cadd78d95d7c","executionInfo":{"status":"ok","timestamp":1541396013008,"user_tz":-540,"elapsed":29502,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n","                    epochs=NUM_EPOCHS,\n","                    callbacks=[TensorBoard(LOG_DIR)],\n","                    validation_data=(Xtest, Ytest))\n","\n","# evaluate model\n","score = model.evaluate(Xtest, Ytest, verbose=1)\n","print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(score[0], score[1]))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Train on 4960 samples, validate on 2126 samples\n","Epoch 1/20\n","4960/4960 [==============================] - 4s 782us/step - loss: 0.3100 - acc: 0.8911 - val_loss: 0.0395 - val_acc: 0.9845\n","Epoch 2/20\n","4960/4960 [==============================] - 1s 139us/step - loss: 0.0205 - acc: 0.9923 - val_loss: 0.0208 - val_acc: 0.9925\n","Epoch 3/20\n","4960/4960 [==============================] - 1s 155us/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0175 - val_acc: 0.9939\n","Epoch 4/20\n","4960/4960 [==============================] - 1s 156us/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0167 - val_acc: 0.9953\n","Epoch 5/20\n","4960/4960 [==============================] - 1s 157us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0164 - val_acc: 0.9934\n","Epoch 6/20\n","4960/4960 [==============================] - 1s 164us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0160 - val_acc: 0.9929\n","Epoch 7/20\n","4960/4960 [==============================] - 1s 160us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0161 - val_acc: 0.9958\n","Epoch 8/20\n","4960/4960 [==============================] - 1s 164us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0158 - val_acc: 0.9962\n","Epoch 9/20\n","4960/4960 [==============================] - 1s 168us/step - loss: 9.6072e-04 - acc: 0.9996 - val_loss: 0.0159 - val_acc: 0.9948\n","Epoch 10/20\n","4960/4960 [==============================] - 1s 167us/step - loss: 7.8549e-04 - acc: 0.9998 - val_loss: 0.0158 - val_acc: 0.9939\n","Epoch 11/20\n","4960/4960 [==============================] - 1s 167us/step - loss: 9.2373e-04 - acc: 0.9998 - val_loss: 0.0157 - val_acc: 0.9958\n","Epoch 12/20\n","4960/4960 [==============================] - 1s 166us/step - loss: 8.8358e-04 - acc: 0.9998 - val_loss: 0.0164 - val_acc: 0.9939\n","Epoch 13/20\n","4960/4960 [==============================] - 1s 166us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0161 - val_acc: 0.9939\n","Epoch 14/20\n","4960/4960 [==============================] - 1s 169us/step - loss: 7.6681e-04 - acc: 0.9996 - val_loss: 0.0160 - val_acc: 0.9958\n","Epoch 15/20\n","4960/4960 [==============================] - 1s 160us/step - loss: 9.2738e-04 - acc: 0.9996 - val_loss: 0.0157 - val_acc: 0.9958\n","Epoch 16/20\n","4960/4960 [==============================] - 1s 164us/step - loss: 5.7211e-04 - acc: 0.9998 - val_loss: 0.0169 - val_acc: 0.9958\n","Epoch 17/20\n","4960/4960 [==============================] - 1s 164us/step - loss: 8.6316e-04 - acc: 0.9998 - val_loss: 0.0169 - val_acc: 0.9939\n","Epoch 18/20\n","4960/4960 [==============================] - 1s 169us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0164 - val_acc: 0.9958\n","Epoch 19/20\n","4960/4960 [==============================] - 1s 165us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0168 - val_acc: 0.9939\n","Epoch 20/20\n","4960/4960 [==============================] - 1s 160us/step - loss: 8.0844e-04 - acc: 0.9998 - val_loss: 0.0169 - val_acc: 0.9958\n","2126/2126 [==============================] - 0s 92us/step\n","Test score: 0.017, accuracy: 0.996\n"],"name":"stdout"}]},{"metadata":{"id":"k0D-I9wsXCxo","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}