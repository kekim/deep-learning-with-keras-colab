{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_skipgram_example.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"yK3LuuH3otQn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"bc7654a4-eb0a-4c13-b533-ef1709871c06","executionInfo":{"status":"ok","timestamp":1541148983614,"user_tz":-540,"elapsed":2054,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","from __future__ import print_function\n","\n","from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n","from keras.preprocessing.sequence import skipgrams\n","\n","text = \"I love green eggs and ham .\"\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([text])\n","\n","word2id = tokenizer.word_index\n","id2word = {v: k for k, v in word2id.items()}\n","\n","wids = [word2id[w] for w in text_to_word_sequence(text)]\n","pairs, labels = skipgrams(wids, len(word2id), window_size=1)\n","print(len(pairs), len(labels))\n","for i in range(10):\n","    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n","        id2word[pairs[i][0]], pairs[i][0], \n","        id2word[pairs[i][1]], pairs[i][1],\n","        labels[i]))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["20 20\n","(eggs (4), and (5)) -> 0\n","(and (5), eggs (4)) -> 0\n","(love (2), green (3)) -> 1\n","(ham (6), love (2)) -> 0\n","(i (1), i (1)) -> 0\n","(eggs (4), i (1)) -> 0\n","(green (3), eggs (4)) -> 1\n","(i (1), love (2)) -> 1\n","(and (5), i (1)) -> 0\n","(and (5), ham (6)) -> 1\n"],"name":"stdout"}]}]}