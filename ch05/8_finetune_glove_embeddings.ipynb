{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8_finetune_glove_embeddings.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"-l4L-WPiUd14","colab_type":"code","outputId":"ce25a5eb-ad48-4f9c-87f1-dbc4390c03b5","executionInfo":{"status":"ok","timestamp":1541397320958,"user_tz":-540,"elapsed":2229,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","from __future__ import print_function\n","import os\n","import collections\n","\n","import nltk\n","import numpy as np\n","from keras.callbacks import TensorBoard\n","from keras.layers import Dense, Dropout, Conv1D, Embedding, GlobalMaxPooling1D\n","from keras.models import Sequential\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","import codecs\n","\n","np.random.seed(42)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"KNIudl49Uhgh","colab_type":"code","outputId":"f20c8d33-f56f-4328-d610-f5793bc53d67","executionInfo":{"status":"ok","timestamp":1541395899807,"user_tz":-540,"elapsed":4432,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"cell_type":"code","source":["!mkdir data\n","!wget https://raw.githubusercontent.com/chen0040/keras-sentiment-analysis-web-api/master/demo/data/umich-sentiment-train.txt -P ./data"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘data’: File exists\n","--2018-11-05 05:31:38--  https://raw.githubusercontent.com/chen0040/keras-sentiment-analysis-web-api/master/demo/data/umich-sentiment-train.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 447539 (437K) [text/plain]\n","Saving to: ‘./data/umich-sentiment-train.txt’\n","\n","umich-sentiment-tra 100%[===================>] 437.05K  --.-KB/s    in 0.08s   \n","\n","2018-11-05 05:31:38 (5.14 MB/s) - ‘./data/umich-sentiment-train.txt’ saved [447539/447539]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"qN9KrEj8bXaH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"outputId":"d61e6f99-9940-460f-8c60-9e0f91e96505","executionInfo":{"status":"ok","timestamp":1541397286178,"user_tz":-540,"elapsed":103406,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["!wget http://nlp.stanford.edu/data/glove.6B.zip -P ./data\n","!unzip ./data/glove.6B.zip -d ./data"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2018-11-05 05:53:04--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2018-11-05 05:53:04--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘./data/glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  6.84MB/s    in 74s     \n","\n","2018-11-05 05:54:19 (11.1 MB/s) - ‘./data/glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  ./data/glove.6B.zip\n","  inflating: ./data/glove.6B.50d.txt  \n","  inflating: ./data/glove.6B.100d.txt  \n","  inflating: ./data/glove.6B.200d.txt  \n","  inflating: ./data/glove.6B.300d.txt  \n"],"name":"stdout"}]},{"metadata":{"id":"cwAiJPKza5h0","colab_type":"code","colab":{}},"cell_type":"code","source":["INPUT_FILE = \"./data/umich-sentiment-train.txt\"\n","GLOVE_MODEL = \"./data/glove.6B.300d.txt\"\n","LOG_DIR = \"./logs\"\n","VOCAB_SIZE = 5000\n","EMBED_SIZE = 300\n","NUM_FILTERS = 256\n","NUM_WORDS = 3\n","BATCH_SIZE = 64\n","NUM_EPOCHS = 10"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pu98C8eOcC5I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0d6ce561-8789-4927-ea9d-361c378aa524","executionInfo":{"status":"ok","timestamp":1541397328856,"user_tz":-540,"elapsed":3419,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["counter = collections.Counter()\n","with codecs.open(INPUT_FILE, \"r\", encoding=\"utf-8\") as fin:\n","    maxlen = 0\n","    for line in fin:\n","        _, sent = line.strip().split(\"\\t\")\n","        try:\n","            words = [x.lower() for x in nltk.word_tokenize(sent)]\n","        except LookupError:\n","            print(\"Englisth tokenize does not downloaded. So download it.\")\n","            nltk.download(\"punkt\")\n","            words = [x.lower() for x in nltk.word_tokenize(sent)]\n","        if len(words) > maxlen:\n","            maxlen = len(words)\n","        for word in words:\n","            counter[word] += 1\n","\n","word2index = collections.defaultdict(int)\n","for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n","    word2index[word[0]] = wid + 1\n","vocab_sz = len(word2index) + 1\n","index2word = {v: k for k, v in word2index.items()}\n","\n","xs, ys = [], []\n","with codecs.open(INPUT_FILE, \"r\", encoding=\"utf-8\") as fin:\n","    for line in fin:\n","        label, sent = line.strip().split(\"\\t\")\n","        ys.append(int(label))\n","        words = [x.lower() for x in nltk.word_tokenize(sent)]\n","        wids = [word2index[word] for word in words]\n","        xs.append(wids)\n","\n","X = pad_sequences(xs, maxlen=maxlen)\n","Y = np_utils.to_categorical(ys)\n","\n","Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3,\n","                                                random_state=42)\n","print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(4960, 42) (2126, 42) (4960, 2) (2126, 2)\n"],"name":"stdout"}]},{"metadata":{"id":"hGYHxMGlcMtk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"2598973e-63be-4f0a-b852-49be181623a0","executionInfo":{"status":"ok","timestamp":1541397403564,"user_tz":-540,"elapsed":49274,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# load GloVe vectors\n","word2emb = {}\n","with codecs.open(GLOVE_MODEL, \"r\", encoding=\"utf-8\") as fglove:\n","    for line in fglove:\n","        cols = line.strip().split()\n","        word = cols[0]\n","        embedding = np.array(cols[1:], dtype=\"float32\")\n","        word2emb[word] = embedding\n","\n","embedding_weights = np.zeros((vocab_sz, EMBED_SIZE))\n","for word, index in word2index.items():\n","    try:\n","        embedding_weights[index, :] = word2emb[word]\n","    except KeyError:\n","        pass\n","\n","model = Sequential()\n","model.add(Embedding(vocab_sz, EMBED_SIZE, input_length=maxlen,\n","                    weights=[embedding_weights],\n","                    trainable=True))\n","model.add(Dropout(0.2))\n","model.add(Conv1D(filters=NUM_FILTERS, kernel_size=NUM_WORDS,\n","                 activation=\"relu\"))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dense(2, activation=\"softmax\"))\n","model.summary()\n","\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n","              metrics=[\"accuracy\"])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 42, 300)           698700    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 42, 300)           0         \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 40, 256)           230656    \n","_________________________________________________________________\n","global_max_pooling1d_1 (Glob (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 514       \n","=================================================================\n","Total params: 929,870\n","Trainable params: 929,870\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"k0D-I9wsXCxo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":431},"outputId":"80377e67-f9c7-4e25-89c5-47b8dea2ac36","executionInfo":{"status":"ok","timestamp":1541397434888,"user_tz":-540,"elapsed":19282,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n","                    epochs=NUM_EPOCHS,\n","                    callbacks=[TensorBoard(LOG_DIR)],\n","                    validation_data=(Xtest, Ytest))              \n","\n","# evaluate model\n","score = model.evaluate(Xtest, Ytest, verbose=1)\n","print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(score[0], score[1]))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Train on 4960 samples, validate on 2126 samples\n","Epoch 1/10\n","4960/4960 [==============================] - 3s 595us/step - loss: 0.1239 - acc: 0.9470 - val_loss: 0.0325 - val_acc: 0.9873\n","Epoch 2/10\n","4960/4960 [==============================] - 1s 197us/step - loss: 0.0166 - acc: 0.9964 - val_loss: 0.0238 - val_acc: 0.9929\n","Epoch 3/10\n","4960/4960 [==============================] - 1s 193us/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0219 - val_acc: 0.9920\n","Epoch 4/10\n","4960/4960 [==============================] - 1s 194us/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.0190 - val_acc: 0.9934\n","Epoch 5/10\n","4960/4960 [==============================] - 1s 196us/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0190 - val_acc: 0.9929\n","Epoch 6/10\n","4960/4960 [==============================] - 1s 196us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0209 - val_acc: 0.9920\n","Epoch 7/10\n","4960/4960 [==============================] - 1s 197us/step - loss: 0.0020 - acc: 0.9998 - val_loss: 0.0188 - val_acc: 0.9934\n","Epoch 8/10\n","4960/4960 [==============================] - 1s 193us/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0207 - val_acc: 0.9944\n","Epoch 9/10\n","4960/4960 [==============================] - 1s 191us/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0192 - val_acc: 0.9934\n","Epoch 10/10\n","4960/4960 [==============================] - 1s 196us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0206 - val_acc: 0.9934\n","2126/2126 [==============================] - 0s 81us/step\n","Test score: 0.021, accuracy: 0.993\n"],"name":"stdout"}]},{"metadata":{"id":"ySln6EbmcgZ5","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}